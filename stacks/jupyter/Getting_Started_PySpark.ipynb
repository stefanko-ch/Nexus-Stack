{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with PySpark\n",
    "\n",
    "This notebook is pre-configured to connect to the **Apache Spark cluster**.\n",
    "The `spark` (SparkSession) and `sc` (SparkContext) variables are automatically available.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verify Cluster Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark and sc are auto-injected by the PySpark kernel\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Master:        {sc.master}\")\n",
    "print(f\"App ID:        {sc.applicationId}\")\n",
    "print(f\"App name:      {spark.sparkContext.appName}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"Alice\", \"Engineering\", 85000),\n",
    "    (\"Bob\", \"Marketing\", 72000),\n",
    "    (\"Charlie\", \"Engineering\", 92000),\n",
    "    (\"Diana\", \"Marketing\", 68000),\n",
    "    (\"Eve\", \"Engineering\", 95000),\n",
    "    (\"Frank\", \"Sales\", 78000),\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"name\", \"department\", \"salary\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DataFrame Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and sort\n",
    "df.filter(df.salary > 75000).orderBy(\"salary\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation by department\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.groupBy(\"department\").agg(\n",
    "    F.count(\"name\").alias(\"employees\"),\n",
    "    F.avg(\"salary\").alias(\"avg_salary\"),\n",
    "    F.max(\"salary\").alias(\"max_salary\"),\n",
    ").orderBy(\"department\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register as SQL table\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "# Query with Spark SQL\n",
    "spark.sql(\"\"\"\n",
    "    SELECT department,\n",
    "           COUNT(*) AS headcount,\n",
    "           ROUND(AVG(salary), 0) AS avg_salary\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    "    ORDER BY avg_salary DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spark SQL Magic Cells\n",
    "\n",
    "Use `%%sparksql` to write SQL directly in a cell (auto-loaded on startup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sparksql\n",
    "SELECT name, department, salary\n",
    "FROM employees\n",
    "WHERE salary > 80000\n",
    "ORDER BY salary DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cluster Info\n",
    "\n",
    "Check the **Spark Master Web UI** for detailed cluster monitoring:\n",
    "- Workers, running applications, completed jobs\n",
    "- Available at `https://spark.YOUR_DOMAIN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster resources\n",
    "print(f\"Default parallelism: {sc.defaultParallelism}\")\n",
    "print(f\"Spark UI: {sc.uiWebUrl}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Spark Cluster)",
   "language": "python",
   "name": "pyspark_cluster"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
